## bit
In computing, a bit (short for "binary digit") is the smallest unit of information that can be processed and stored by a computer. A bit can have one of two values: 0 or 1.

### Byte
Bits are typically grouped together into larger units called bytes,  which are composed of 8 bits. 
This allows computers to represent and process larger values, such as numbers and characters. For example, a 32-bit integer uses 4 bytes, or 32 bits, to represent a whole number within a certain range.

In addition to bytes, bits can also be grouped together into other units such as kilobits (Kb), megabits (Mb), and gigabits (Gb) to represent larger amounts of data or network speeds. For example, ==a network connection with a speed of 100 megabits per second (100 Mbps)== can transfer 100 million bits of data per second.

#### Here are the typical memory sizes for some common data types used in programming:

- **Boolean**:  *1 bit* (can only store true or false values)
- **Char**: *1 byte (8 bits)* (typically used to store a single character)
- **Short int**: 2 bytes (can represent integer values from -32,768 to 32,767)
- **Int (32-bit int)**: 4 bytes  (can represent integer values from -2,147,483,648 to 2,147,483,647)
- **Long int (64-bit Int)**: 8 bytes (can represent integer values from -9,223,372,036,854,775,808 to 9,223,372,036,854,775,807)
- **Float**: 4 bytes (can represent decimal values with 7 significant digits)
- **Double**: 8 bytes (can represent decimal values with 15-16 significant digits)


